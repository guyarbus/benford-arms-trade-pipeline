{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80264bd6",
   "metadata": {},
   "source": [
    "# NOTEBOOK 01 : DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfa9f2",
   "metadata": {},
   "source": [
    "**Author** : Guy Arbus\n",
    "**Date** : 2026/02/09\n",
    "**Version** : 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e795283",
   "metadata": {},
   "source": [
    "## ABSTRACT\n",
    "\n",
    "The data cleaning phase aimed to ensure the **reliability**, **consistency**, and **operational relevance** of the dataset prior to analysis and modeling.  \n",
    "\n",
    "Raw data were systematically inspected to identify missing values, outliers, duplicates, and incoherent records, particularly those resulting from sensor noise, transmission errors, or adversarial perturbations. Domain-specific rules and statistical thresholds were applied to validate measurements and enforce physical plausibility constraints. Missing or corrupted data were handled using controlled imputation strategies or exclusion when necessary to avoid bias.  \n",
    "\n",
    "This process was essential to reduce noise, enhance signal integrity, and guarantee that downstream analytical and predictive models operate on data aligned with defense and security requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6904e779",
   "metadata": {},
   "source": [
    "## BEST PRACTICES & PRINCIPLES\n",
    "\n",
    "- Always keep raw data unchanged (read-only)\n",
    "- Document every decision and assumption\n",
    "- Version control your cleaning scripts\n",
    "- Make it reproducible (seeds, scripts, environments)\n",
    "- Validate at each step before proceeding\n",
    "- Visualize before and after each major change\n",
    "- Domain expertise consultation when uncertain\n",
    "- Automate repetitive tasks\n",
    "- Test on sample before applying to full dataset\n",
    "- Consider ethical implications (bias, fairness, privacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbef9d",
   "metadata": {},
   "source": [
    "## COMMON PITFALLS TO AVOID\n",
    "\n",
    "- Deleting data without understanding why\n",
    "- Imputing without investigating missingness patterns\n",
    "- Removing outliers that are legitimate\n",
    "- Data leakage (using test set info in cleaning)\n",
    "- Over-cleaning (removing valuable variance)\n",
    "- Ignoring domain knowledge\n",
    "- Not documenting changes\n",
    "- Cleaning test data differently than training data\n",
    "- Assuming correlation implies causation in feature selection\n",
    "- Not validating cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e709a3",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENT\n",
    "\n",
    "### 01. INITIAL DATA ASSESSMENT\n",
    "\n",
    "#### Data Sources\n",
    "#### Collection methods\n",
    "#### Sensitive data classification\n",
    "#### Restrictions\n",
    "#### Data dictionary\n",
    "#### Completeness\n",
    "#### Data structure \n",
    "\n",
    "### 02. HANDLING SENSITIVE DATA AND CLASSIFICATION INFORMATION\n",
    "### 03. STRUCTURAL ISSUES\n",
    "### 04. MISSING DATA\n",
    "### 05. DUPLICATES\n",
    "### 06. OUTLIERS\n",
    "### 07. CONSISTENCY\n",
    "### 08. VALIDATION WITH DOMAIN KNOWLEDGE\n",
    "### 09. CATEGORICAL VARIABLES CLEANING\n",
    "### 10. TEXT DATA CLEANING\n",
    "### 11. TEMPORAL DATA\n",
    "### 12. GEOSPATIAL DATA\n",
    "### 13. NUMERICAL DATA\n",
    "\n",
    "### FEATURE ENGINEERING (PRE-MODELING)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
